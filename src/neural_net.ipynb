{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise sheet 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Most of the content on this sheet is adopted from the free coursera.org course \"Neural Networks and Deep Learning\", Week 4.*\n",
    "\n",
    "we will code all components needed to build and train a (deep) neural network. There will be multiple functions to implement, most of which are followed by a verification block that allows you to check if your function works as expected.\n",
    "\n",
    " \n",
    "\n",
    "**A note on the used notation**:\n",
    "\n",
    "- Superscript $[l]$ denotes a quantity associated with the $l^{th}$ layer. \n",
    "    - Example: $a^{[L]}$ is the $L^{th}$ layer activation. $W^{[L]}$ and $b^{[L]}$ are the $L^{th}$ layer parameters.\n",
    "- Superscript $(i)$ denotes a quantity associated with the $i^{th}$ example. \n",
    "    - Example: $x^{(i)}$ is the $i^{th}$ training example.\n",
    "- Lowerscript $i$ denotes the $i^{th}$ entry of a vector.\n",
    "    - Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the $l^{th}$ layer's activations).\n",
    "\n",
    "\n",
    "We start with loading some standard libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt to plot figures\n",
    "import matplotlib.pyplot as plt\n",
    "# numpy for array/matrix operations\n",
    "import numpy as np\n",
    "# to be able to load matlab data files\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# we set a seed variable for functions that use randomization (e.g. when shuffling data samples)\n",
    "# this way, we can have reproducible results even with randomization\n",
    "RANDOM_STATE = 2\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Outline\n",
    "\n",
    "To build your neural network, you will be implementing several \"helper functions\". These helper functions can be used to build a L-layer neural network. Each small helper function you will implement will have instructions that will walk you through the necessary steps. Here is an outline of this assignment, you will:\n",
    "\n",
    "- Initialize the parameters for an L-layer neural network.\n",
    "- Implement the forward propagation module (shown in purple in the figure below).\n",
    "    - Complete the LINEAR part of a layer's forward propagation step (resulting in output Z).\n",
    "    - Implement activation functions (relu/sigmoid)\n",
    "    - Combine the previous two steps into a new [LINEAR->ACTIVATION] forward function.\n",
    "    - Stack the [LINEAR->RELU] forward function L-1 time (for layers 1 through L-1) and add a [LINEAR->SIGMOID] at the end (for the final layer L). This gives you a new L_model_forward function.\n",
    "- Compute the loss.\n",
    "- Implement the backward propagation module (denoted in red in the figure below).\n",
    "\n",
    "    - Complete the LINEAR part of a layer's backward propagation step.\n",
    "    - Functions for calculating the gradient of the ACTIVATION functions are given (relu_backward/sigmoid_backward)\n",
    "    - Combine the previous two steps into a new [LINEAR->ACTIVATION] backward function.\n",
    "    - Stack [LINEAR->RELU] backward L-1 times and add [LINEAR->SIGMOID] backward in a new L_model_backward function\n",
    "\n",
    "- Finally update the parameters using gradient descent.\n",
    "\n",
    "Note that for every forward function, there is a corresponding backward function. That is why at every step of your forward module you will be storing some values in a cache. The cached values are useful for computing gradients. In the backpropagation module you will then use the cache to calculate the gradients. This assignment will show you exactly how to carry out each of these steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Initialization of L-layer Neural Network\n",
    "\n",
    "Complete implementing the function below to randomly initialize parameters (weight matrices and bias vectors) for a (deep) L-layer neural network. Make sure that dimensions of the parameter matrices/vectors match between each layer (assert calls for this are already implemented).\n",
    "\n",
    "Notes:\n",
    "- Initialize weight matrices with small normal distributed numbers. Use np.random.randn(matrix_shape) * 0.01.\n",
    "- Initialize bias vectors with zeros. Use np.zeros(vector_shape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network:\n",
    "                    e.g. a network with input layer (e.g. 4 features), two hidden layers (e.g. each with 5 nodes)\n",
    "                    and output layer (e.g. 1 node for binary classification using sigmoid activation) would result \n",
    "                    in layer_dims=[4,5,5,1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "                    \n",
    "    \"\"\"\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that code works as expected**\n",
    "\n",
    "Compare output of your implemented function with expected output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-4.16757847e-03 -5.62668272e-04 -2.13619610e-02  1.64027081e-02]\n",
      " [-1.79343559e-02 -8.41747366e-03  5.02881417e-03 -1.24528809e-02]\n",
      " [-1.05795222e-02 -9.09007615e-03  5.51454045e-03  2.29220801e-02]\n",
      " [ 4.15393930e-04 -1.11792545e-02  5.39058321e-03 -5.96159700e-03]\n",
      " [-1.91304965e-04  1.17500122e-02 -7.47870949e-03  9.02525097e-05]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[-8.78107893e-03 -1.56434170e-03  2.56570452e-03 -9.88779049e-03\n",
      "  -3.38821966e-03]\n",
      " [-2.36184031e-03 -6.37655012e-03 -1.18761229e-02 -1.42121723e-02\n",
      "  -1.53495196e-03]\n",
      " [-2.69056960e-03  2.23136679e-02 -2.43476758e-02  1.12726505e-03\n",
      "   3.70444537e-03]\n",
      " [ 1.35963386e-02  5.01857207e-03 -8.44213704e-03  9.76147160e-08\n",
      "   5.42352572e-03]\n",
      " [-3.13508197e-03  7.71011738e-03 -1.86809065e-02  1.73118467e-02\n",
      "   1.46767801e-02]]\n",
      "b2 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Total number of parameters: 61\n"
     ]
    }
   ],
   "source": [
    "example_layer_dims = [4,5,5,1]\n",
    "\n",
    "parameters = initialize_parameters(example_layer_dims)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "\n",
    "total_number_of_parameters = 0\n",
    "for layer in range(1,len(example_layer_dims)):\n",
    "    total_number_of_parameters += np.prod(np.shape(parameters[f\"W{layer}\"]))\n",
    "    total_number_of_parameters += np.prod(np.shape(parameters[f\"b{layer}\"]))\n",
    "print(\"Total number of parameters:\", total_number_of_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output:\n",
    "\n",
    "W1 = [[-4.16757847e-03 -5.62668272e-04 -2.13619610e-02  1.64027081e-02]\n",
    " [-1.79343559e-02 -8.41747366e-03  5.02881417e-03 -1.24528809e-02]\n",
    " [-1.05795222e-02 -9.09007615e-03  5.51454045e-03  2.29220801e-02]\n",
    " [ 4.15393930e-04 -1.11792545e-02  5.39058321e-03 -5.96159700e-03]\n",
    " [-1.91304965e-04  1.17500122e-02 -7.47870949e-03  9.02525097e-05]]\n",
    " \n",
    "b1 = [[0.]\n",
    " [0.]\n",
    " [0.]\n",
    " [0.]\n",
    " [0.]]\n",
    "\n",
    "W2 = [[-8.78107893e-03 -1.56434170e-03  2.56570452e-03 -9.88779049e-03\n",
    "  -3.38821966e-03]\n",
    " [-2.36184031e-03 -6.37655012e-03 -1.18761229e-02 -1.42121723e-02\n",
    "  -1.53495196e-03]\n",
    " [-2.69056960e-03  2.23136679e-02 -2.43476758e-02  1.12726505e-03\n",
    "   3.70444537e-03]\n",
    " [ 1.35963386e-02  5.01857207e-03 -8.44213704e-03  9.76147160e-08\n",
    "   5.42352572e-03]\n",
    " [-3.13508197e-03  7.71011738e-03 -1.86809065e-02  1.73118467e-02\n",
    "   1.46767801e-02]]\n",
    "\n",
    "b2 = [[0.]\n",
    " [0.]\n",
    " [0.]\n",
    " [0.]\n",
    " [0.]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Forward propagation\n",
    "\n",
    "Now that we have initialized the parameters, we implement the forward propagation module. We start by implementing some basic functions that are needed later on. We'll complete three functions in this part:\n",
    "\n",
    "    - LINEAR\n",
    "    - LINEAR -> ACTIVATION where ACTIVATION will be either ReLU or Sigmoid.\n",
    "    - [LINEAR -> RELU] x (L-1) -> LINEAR -> SIGMOID (i.e. whole model)\n",
    "\n",
    "### 3.1) Linear Forward Function\n",
    "\n",
    "We start with the linear forward function. This function calculates the equation:\n",
    "\n",
    "$$Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}$$\n",
    "\n",
    "with $A^{[0]} = X$ (i.e. the matrix of data samples).\n",
    "\n",
    "Remember that $W^{[l]}A^{[l-1]}$ calculates the dot product between two matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    Z = np.dot(W,A) + b\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that code works as expected**\n",
    "\n",
    "Compare output of your implemented function with expected output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = [[-2.66089417]\n",
      " [ 2.83770075]\n",
      " [-2.7214624 ]\n",
      " [ 0.36664977]\n",
      " [-3.21640702]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "example_batch_size = 1  # number of data samples in this batch\n",
    "\n",
    "A = np.random.randn(example_layer_dims[0], example_batch_size)\n",
    "W = np.random.randn(example_layer_dims[1], example_layer_dims[0])\n",
    "b = np.random.randn(example_layer_dims[1], 1)\n",
    "\n",
    "Z, linear_cache = linear_forward(A, W, b)\n",
    "print(\"Z = \" + str(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output: \n",
    "\n",
    "Z = [[-2.66089417]\n",
    " [ 2.83770075]\n",
    " [-2.7214624 ]\n",
    " [ 0.36664977]\n",
    " [-3.21640702]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Activation Functions\n",
    "\n",
    "There are various different activation functions. In this exercise, we implement two activation functions that were presented in the lecture: sigmoid and ReLU. We return the input (Z) as well (for simplification of error backpropagation calculations later on).\n",
    "\n",
    "Note: the backward functions for both activation functions (i.e. derivative including application of chain rule - therefore not exactly the same as in the lecture) is already given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation functions\n",
    "\n",
    "def sigmoid(Z):\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    ### END CODE HERE ###\n",
    "    return A, Z\n",
    "\n",
    "def relu(Z):\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    A = np.maximum(Z,0)\n",
    "    ### END CODE HERE ###\n",
    "    assert(A.shape == Z.shape)\n",
    "    return A, Z\n",
    "\n",
    "\n",
    "# backward functions (includes chain rule application)\n",
    "\n",
    "def sigmoid_backward(dA, Z):    \n",
    "    # version from the lecture:\n",
    "    dZ = dA * np.exp(-Z) / (1 + np.exp(-Z)) ** 2\n",
    "    # alternative version\n",
    "    #s = 1/(1+np.exp(-Z))\n",
    "    #dZ = dA * s * (1 - s)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.zeros(dA.shape)\n",
    "    dZ[Z>0] = 1\n",
    "    dZ *= dA\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Linear Activation Forward Function\n",
    "\n",
    "One layer in a neural network usually consists of a linear function that is followed by an activation function (and thus the two combined are counted as one layer). For convenience, we group these two operations into one function (LINEAR->ACTIVATION). Implement a function that does the LINEAR forward step followed by an ACTIVATION forward step.\n",
    "\n",
    "The mathematical formulation is given as: \n",
    "$A^{[l]} = g(Z^{[l]}) = g(W^{[l]}A^{[l-1]} +b^{[l]})$ \n",
    "\n",
    "where the activation \"g\" can be sigmoid() or relu(). Use linear_forward() from 3.1) and the correct activation function from 3.2) to implement the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python tuple containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b) # This \"linear_cache\" contains (A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z) # This \"activation_cache\" contains \"Z\"\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b) # This \"linear_cache\" contains (A_prev, W, b)\n",
    "        A, activation_cache = relu(Z) # This \"activation_cache\" contains \"Z\"\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that code works as expected**\n",
    "\n",
    "Compare output of your implemented function with expected output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With sigmoid: A = [[0.06532072]\n",
      " [0.94467943]\n",
      " [0.06171873]\n",
      " [0.5906492 ]\n",
      " [0.03855294]]\n",
      "With ReLU: A = [[0.        ]\n",
      " [2.83770075]\n",
      " [0.        ]\n",
      " [0.36664977]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "example_batch_size = 1  # number of data samples in this batch\n",
    "\n",
    "A_prev = np.random.randn(example_layer_dims[0], example_batch_size)\n",
    "W = np.random.randn(example_layer_dims[1], example_layer_dims[0])\n",
    "b = np.random.randn(example_layer_dims[1], 1) \n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"sigmoid\")\n",
    "print(\"With sigmoid: A = \" + str(A))\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"relu\")\n",
    "print(\"With ReLU: A = \" + str(A))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output:\n",
    "    \n",
    "With sigmoid: A = [[0.06532072]\n",
    " [0.94467943]\n",
    " [0.06171873]\n",
    " [0.5906492 ]\n",
    " [0.03855294]]\n",
    " \n",
    "With ReLU: A = [[0.        ]\n",
    " [2.83770075]\n",
    " [0.        ]\n",
    " [0.36664977]\n",
    " [0.        ]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) L-Layer Model\n",
    "\n",
    "We can now use the implemented functions to build an L-layer neural network with a sigmoid activation function in the output layer. Write a function that creates a neural network with L-1 layers using linear_activation_forward with ReLU activation, then finishes with the output layer, using linear_activation_forward with sigmoid activation.\n",
    "\n",
    "Note on counting layers: when counting layers in a neural network, we only count layers with learnable parameters (weight matrices / bias vectors). This is why the input layer is usually NOT counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], \"relu\")\n",
    "        caches.append(cache)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that code works as expected**\n",
    "\n",
    "Compare output of your implemented function with expected output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL = [[0.49999827]]\n",
      "Length of caches list = 3\n"
     ]
    }
   ],
   "source": [
    "example_layer_dims = [4,5,5,1]\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "example_batch_size = 1  # number of data samples in this batch\n",
    "\n",
    "A_prev = np.random.randn(example_layer_dims[0], example_batch_size)\n",
    "W = np.random.randn(example_layer_dims[1], example_layer_dims[0])\n",
    "b = np.random.randn(example_layer_dims[1], 1)\n",
    "\n",
    "X = A_prev\n",
    "parameters = initialize_parameters(example_layer_dims)\n",
    "\n",
    "\n",
    "AL, caches = L_model_forward(X, parameters)\n",
    "print(\"AL = \" + str(AL))\n",
    "print(\"Length of caches list = \" + str(len(caches)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output:\n",
    "\n",
    "AL = [[0.49999827]]  \n",
    "Length of caches list = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Loss function\n",
    "\n",
    "So far we have implemented an L-layer neural network with full forward propagation, that takes input X (matrix of samples) and outputs a row vector containing the network's predictions. We also store all intermediate values that are calculated during forward propagation in \"caches\". Output of the neural net is given in $A^{[L]}$, which we can use to compute the loss of the net's predictions.\n",
    "\n",
    "We will now implement the loss calculation. In this exercise, we use binary cross entropy loss, which is given as:\n",
    "\n",
    "$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\ln\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\ln\\left(1- a^{[L](i)}\\right))$$\n",
    "\n",
    "with  \n",
    "m = number of samples  \n",
    "$a^{[L]}$ = output of the model   \n",
    "y = ground truth class (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    ### START CODE HERE ### (≈ 1 lines of code)\n",
    "    cost = (-1/m) * (np.dot(Y, np.log(AL).T) + np.dot((1-Y), np.log(1-AL).T))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that code works as expected**\n",
    "\n",
    "Compare output of your implemented function with expected output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.6931437185364475\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "Y = np.array(np.random.randint(0,1, size=(1,1)))\n",
    "\n",
    "#Y, AL = compute_cost_test_case()\n",
    "\n",
    "print(\"cost = \" + str(compute_cost(AL, Y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output:\n",
    "    \n",
    "cost = 0.6931437185364475"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Backward propagation\n",
    "\n",
    "Following the forward propagation of our network, we now need to implement helper functions for backpropagation. Remember that backpropagation is used to calculate the gradient of the loss function with respect to the parameters, so that we can update them using gradient descent and reduce the defined loss (and classification error as a consequence). These weight/bias updates represent learning of the network.\n",
    "\n",
    "Similar to forward propagation, we build the backward propagation in three steps:\n",
    "\n",
    "- LINEAR backward\n",
    "- LINEAR -> ACTIVATION backward where ACTIVATION computes the derivative of either the ReLU or sigmoid activation\n",
    "[LINEAR -> RELU]\n",
    "- (L-1) -> LINEAR -> SIGMOID backward (whole model)\n",
    "\n",
    "### 5.1) Linear backward function\n",
    "\n",
    "For layer $l$, the linear (forward) function is given as: $Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$ (followed by an activation).\n",
    "\n",
    "Suppose we have already calculated the derivative $dZ^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial Z^{[l]}}$. We need to get $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$ which are used by gradient descent to update the parameters $(W^{[l]}, b^{[l]})$.\n",
    "\n",
    "$dW^{[l]}, db^{[l]}, dA^{[l-1]}$ are computed using $dZ^{[l]}$ as follows:\n",
    "\n",
    "$$ dW^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T}$$\n",
    "$$ db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}$$\n",
    "$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]}$$\n",
    "\n",
    "Use these formulas as reference to implement the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    # Here cache is \"linear_cache\" containing (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    dW = (1/m) * np.dot(dZ, A_prev.T)\n",
    "    db = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that code works as expected**\n",
    "\n",
    "Compare output of your implemented function with expected output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_prev = [[-0.00167838]\n",
      " [ 0.00305669]\n",
      " [ 0.00023985]\n",
      " [-0.00414566]\n",
      " [ 0.00043855]]\n",
      "dW = [[0.         0.         0.         0.00041755 0.        ]]\n",
      "db = [[0.49999827]]\n"
     ]
    }
   ],
   "source": [
    "example_layer_dims = [4,10,10,1]\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "#example_batch_size = 1  # number of data samples in this batch\n",
    "\n",
    "#A_prev = np.random.randn(example_layer_dims[2], example_batch_size)\n",
    "#W = np.random.randn(example_layer_dims[3], example_layer_dims[2])\n",
    "#b = np.random.randn(example_layer_dims[3], 1)\n",
    "\n",
    "#linear_cache = (A_prev, W, b)\n",
    "linear_cache = caches[-1][0]\n",
    "\n",
    "#Z, _ = linear_forward(A_prev, W, b)\n",
    "\n",
    "Z, _ = linear_forward(linear_cache[0], linear_cache[1], linear_cache[2])\n",
    "\n",
    "dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "dZ = sigmoid_backward(dAL, Z)\n",
    "\n",
    "#dZ, linear_cache = linear_backward_test_case()\n",
    "dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output:\n",
    "    \n",
    "dA_prev = [[-0.00167838]\n",
    " [ 0.00305669]\n",
    " [ 0.00023985]\n",
    " [-0.00414566]\n",
    " [ 0.00043855]]\n",
    " \n",
    "dW = [[0.         0.         0.         0.00041755 0.        ]]\n",
    "\n",
    "db = [[0.49999827]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Linear activation backward function\n",
    "\n",
    "Next, we'll implement a function that merges the backward step in linear_backward and the backward step for the activation function, i.e. we implement the backpropgation for a layer consisting of LINEAR->ACTIVATION. Note that we have already implemented the backward step (i.e. calculation of the derivative) for the activation functions sigmoid and ReLU with consideration of the chain rule used in backpropagation further above (called sigmoid_backward and relu_backward). \n",
    "Mathematically, what happens in those functions is that if $g(.)$ is the activation function, then \n",
    "    `sigmoid_backward` and `relu_backward` compute $$dZ^{[l]} = dA^{[l]} * g'(Z^{[l]})$$\n",
    "    \n",
    "Use sigmoid_backward, relu_backward and linear_backward to complete the function below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that code works as expected**\n",
    "\n",
    "Compare output of your implemented function with expected output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid:\n",
      "dA_prev = [[-0.00167838]\n",
      " [ 0.00305669]\n",
      " [ 0.00023985]\n",
      " [-0.00414566]\n",
      " [ 0.00043855]]\n",
      "dW = [[0.         0.         0.         0.00041755 0.        ]]\n",
      "db = [[0.49999827]]\n",
      "\n",
      "relu:\n",
      "dA_prev = [[-5.63658256e-05]\n",
      " [-2.08053040e-05]\n",
      " [ 3.49982475e-05]\n",
      " [-4.04677628e-10]\n",
      " [-2.24841050e-05]]\n",
      "dW = [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-3.08050683e-04  0.00000000e+00 -1.27432876e-04  0.00000000e+00\n",
      "  -6.44344527e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "db = [[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.00414566]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "linear_activation_cache = caches[-1]\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(dAL, linear_activation_cache, activation = \"sigmoid\")\n",
    "print (\"sigmoid:\")\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db) + \"\\n\")\n",
    "\n",
    "linear_activation_cache = caches[-2]\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(dA_prev, linear_activation_cache, activation = \"relu\")\n",
    "print (\"relu:\")\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output:\n",
    "\n",
    "\n",
    "##### sigmoid:\n",
    "\n",
    "sigmoid:\n",
    "dA_prev = [[-0.00167838]\n",
    " [ 0.00305669]\n",
    " [ 0.00023985]\n",
    " [-0.00414566]\n",
    " [ 0.00043855]]\n",
    " \n",
    "dW = [[0.         0.         0.         0.00041755 0.        ]]\n",
    "\n",
    "db = [[0.49999827]]\n",
    "\n",
    "\n",
    "##### relu:\n",
    "\n",
    "dA_prev = [[-5.63658256e-05]\n",
    " [-2.08053040e-05]\n",
    " [ 3.49982475e-05]\n",
    " [-4.04677628e-10]\n",
    " [-2.24841050e-05]]\n",
    " \n",
    "dW = [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
    "   0.00000000e+00]\n",
    " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
    "   0.00000000e+00]\n",
    " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
    "   0.00000000e+00]\n",
    " [-3.08050683e-04  0.00000000e+00 -1.27432876e-04  0.00000000e+00\n",
    "  -6.44344527e-05]\n",
    " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
    "   0.00000000e+00]]\n",
    "\n",
    "db = [[ 0.        ]\n",
    " [ 0.        ]\n",
    " [ 0.        ]\n",
    " [-0.00414566]\n",
    " [ 0.        ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) L-Layer Model Backward\n",
    "\n",
    "We can now implement the loss backpropagation for the whole network. Recall that when we run the L_model_forward function, in each step we store a cache which contains (A,W,b, and Z). In the backpropagation module, we'll use those variables to compute the gradients. Therefore, in the L_model_backward function, we go through all the hidden layers backward, starting from layer L. In each step, we use the cached values for the l-th layer to backpropagate the error through that layer.\n",
    "\n",
    "**Initializing backpropagation:** To backpropagate the loss through our network with final sigmoid activation in the output layer, we know that the output is given as: $A^{[L]} = \\sigma(Z^{[L]})$\n",
    ". Our code thus needs to compute $dAL= \\frac{\\partial \\mathcal{L}}{\\partial A^{[L]}}$, where $\\mathcal{L}$ is our loss function.\n",
    "\n",
    "Thus, we need the partial derivative of our loss function with respect to AL, which is given by the following formula:\n",
    "\n",
    "$dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))$\n",
    "\n",
    "We can use this post-activation gradient dAL to keep going backward by feeding dAL into our LINEAR->SIGMOID backward function (which will use the cached values stored by the L_model_forward function). After that, we'll have to use a for loop to iterate through all the remaining layers using our LINEAR->RELU backward function. As output of the function, all calculated dA, dW, and db (i.e. for each layer) has to be stored in a python dict (called \"grads\", see below) using the naming conventions outlined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    current_cache = caches[L-1] # Last Layer\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        ### START CODE HERE ### (approx. 5 lines)\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that code works as expected**\n",
    "\n",
    "Compare output of your implemented function with expected output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW1 = [[ 2.34909002e-05  3.17152617e-06  1.20408457e-04 -9.24552184e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.45857943e-05 -1.96924035e-06 -7.47631197e-05  5.74066037e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 9.37042720e-06  1.26510925e-06  4.80304573e-05 -3.68800211e-05]]\n",
      "db1 = [[-5.63658256e-05]\n",
      " [ 0.00000000e+00]\n",
      " [ 3.49982475e-05]\n",
      " [ 0.00000000e+00]\n",
      " [-2.24841050e-05]]\n",
      "dA1 = [[-5.63658256e-05]\n",
      " [-2.08053040e-05]\n",
      " [ 3.49982475e-05]\n",
      " [-4.04677628e-10]\n",
      " [-2.24841050e-05]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AL, Y_assess, caches = L_model_backward_test_case()\n",
    "\n",
    "grads = L_model_backward(AL, Y, caches)\n",
    "#print_grads(grads)\n",
    "print(\"dW1 = {}\\ndb1 = {}\\ndA1 = {}\\n\".format(grads['dW1'], grads['db1'], grads['dA1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output:\n",
    "\n",
    "dW1 = [[ 2.34909002e-05  3.17152617e-06  1.20408457e-04 -9.24552184e-05]\n",
    " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
    " [-1.45857943e-05 -1.96924035e-06 -7.47631197e-05  5.74066037e-05]\n",
    " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
    " [ 9.37042720e-06  1.26510925e-06  4.80304573e-05 -3.68800211e-05]]\n",
    "\n",
    "db1 = [[-5.63658256e-05]\n",
    " [ 0.00000000e+00]\n",
    " [ 3.49982475e-05]\n",
    " [ 0.00000000e+00]\n",
    " [-2.24841050e-05]]\n",
    "\n",
    "dA1 = [[-5.63658256e-05]\n",
    " [-2.08053040e-05]\n",
    " [ 3.49982475e-05]\n",
    " [-4.04677628e-10]\n",
    " [-2.24841050e-05]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4) Update parameters\n",
    "\n",
    "We now have everything to update the parameters (weight matrices and bias vectors) of the model using gradient descent. These updates are essentially what constitutes \"learning\" in the neural network. We update weights and biases as follows:\n",
    "\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} $$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} $$\n",
    "\n",
    "where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "    ### END CODE HERE ###\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that code works as expected**\n",
    "\n",
    "Compare output of your implemented function with expected output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-4.16992756e-03 -5.62985425e-04 -2.13740018e-02  1.64119536e-02]\n",
      " [-1.79343559e-02 -8.41747366e-03  5.02881417e-03 -1.24528809e-02]\n",
      " [-1.05780636e-02 -9.08987923e-03  5.52201676e-03  2.29163395e-02]\n",
      " [ 4.15393930e-04 -1.11792545e-02  5.39058321e-03 -5.96159700e-03]\n",
      " [-1.92242008e-04  1.17498857e-02 -7.48351254e-03  9.39405118e-05]]\n",
      "b1 = [[ 5.63658256e-06]\n",
      " [ 0.00000000e+00]\n",
      " [-3.49982475e-06]\n",
      " [ 0.00000000e+00]\n",
      " [ 2.24841050e-06]]\n",
      "W2 = [[-8.78107893e-03 -1.56434170e-03  2.56570452e-03 -9.88779049e-03\n",
      "  -3.38821966e-03]\n",
      " [-2.36184031e-03 -6.37655012e-03 -1.18761229e-02 -1.42121723e-02\n",
      "  -1.53495196e-03]\n",
      " [-2.69056960e-03  2.23136679e-02 -2.43476758e-02  1.12726505e-03\n",
      "   3.70444537e-03]\n",
      " [ 1.36271437e-02  5.01857207e-03 -8.42939375e-03  9.76147160e-08\n",
      "   5.42996917e-03]\n",
      " [-3.13508197e-03  7.71011738e-03 -1.86809065e-02  1.73118467e-02\n",
      "   1.46767801e-02]]\n",
      "b2 = [[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.00041457]\n",
      " [0.        ]]\n",
      "W3 = [[-0.00335677  0.00611341  0.00047971 -0.00833311  0.0008771 ]]\n",
      "b3 = [[-0.04999983]]\n"
     ]
    }
   ],
   "source": [
    "parameters = update_parameters(parameters, grads, 0.1)\n",
    "\n",
    "print (\"W1 = \"+ str(parameters[\"W1\"]))\n",
    "print (\"b1 = \"+ str(parameters[\"b1\"]))\n",
    "print (\"W2 = \"+ str(parameters[\"W2\"]))\n",
    "print (\"b2 = \"+ str(parameters[\"b2\"]))\n",
    "print (\"W3 = \"+ str(parameters[\"W3\"]))\n",
    "print (\"b3 = \"+ str(parameters[\"b3\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output:\n",
    "\n",
    "W1 = [[-4.16992756e-03 -5.62985425e-04 -2.13740018e-02  1.64119536e-02]\n",
    " [-1.79343559e-02 -8.41747366e-03  5.02881417e-03 -1.24528809e-02]\n",
    " [-1.05780636e-02 -9.08987923e-03  5.52201676e-03  2.29163395e-02]\n",
    " [ 4.15393930e-04 -1.11792545e-02  5.39058321e-03 -5.96159700e-03]\n",
    " [-1.92242008e-04  1.17498857e-02 -7.48351254e-03  9.39405118e-05]]\n",
    "\n",
    "b1 = [[ 5.63658256e-06]\n",
    " [ 0.00000000e+00]\n",
    " [-3.49982475e-06]\n",
    " [ 0.00000000e+00]\n",
    " [ 2.24841050e-06]]\n",
    "\n",
    "W2 = [[-8.78107893e-03 -1.56434170e-03  2.56570452e-03 -9.88779049e-03\n",
    "  -3.38821966e-03]\n",
    " [-2.36184031e-03 -6.37655012e-03 -1.18761229e-02 -1.42121723e-02\n",
    "  -1.53495196e-03]\n",
    " [-2.69056960e-03  2.23136679e-02 -2.43476758e-02  1.12726505e-03\n",
    "   3.70444537e-03]\n",
    " [ 1.36271437e-02  5.01857207e-03 -8.42939375e-03  9.76147160e-08\n",
    "   5.42996917e-03]\n",
    " [-3.13508197e-03  7.71011738e-03 -1.86809065e-02  1.73118467e-02\n",
    "   1.46767801e-02]]\n",
    "\n",
    "b2 = [[0.        ]\n",
    " [0.        ]\n",
    " [0.        ]\n",
    " [0.00041457]\n",
    " [0.        ]]\n",
    "\n",
    "W3 = [[-0.00335677  0.00611341  0.00047971 -0.00833311  0.0008771 ]]\n",
    "\n",
    "b3 = [[-0.04999983]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Optional\n",
    "\n",
    "We now have implemented all functions that are needed to build and train a deep neural network for a binary classification task. Try putting it all together and train a DNN for the last binary classification task on Exercise sheet 3 (data given in \"ex3data2.mat\").   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of model training using our own implemented neural network functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.001, num_iterations = 100, print_cost=False, parameters=None):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization.\n",
    "    if parameters is None:\n",
    "        parameters = initialize_parameters(layers_dims)\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "\n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 1000== 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to evaluate our neural network with a given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the dataset from last week\n",
    "Note that your notebook needs to be able to access the datafile ex3data2.mat from last exercise sheet (e.g. just dump it in the same folder as this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### Load new dataset\n",
    "raw_data = loadmat('ex3data2.mat')  # datafile from last exercise sheet\n",
    "X_all,y_all = raw_data['X'], raw_data['y']\n",
    "\n",
    "# visualize the data\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(X_all[np.where(y_all==1)[0],0],X_all[np.where(y_all==1)[0],1], s=50, marker='x', label='Positive')\n",
    "ax.scatter(X_all[np.where(y_all==0)[0],0],X_all[np.where(y_all==0)[0],1], s=50, marker='o', label='Negative')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# for comparison/reproducibility \n",
    "RANDOM_STATE = 2\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# create train/val/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.20, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# z-normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_st = scaler.transform(X_train)\n",
    "X_test_st = scaler.transform(X_test)\n",
    "\n",
    "# change sample representation to match expected input in our NN implementation\n",
    "X_train_st = np.swapaxes(X_train_st, 0,1)\n",
    "X_test_st = np.swapaxes(X_test_st, 0,1)\n",
    "y_train = np.swapaxes(y_train, 0,1)\n",
    "y_test = np.swapaxes(y_test, 0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693070\n",
      "Cost after iteration 1000: 0.690272\n",
      "Cost after iteration 2000: 0.688563\n",
      "Cost after iteration 3000: 0.687511\n",
      "Cost after iteration 4000: 0.686854\n",
      "Cost after iteration 5000: 0.686433\n",
      "Cost after iteration 6000: 0.686152\n",
      "Cost after iteration 7000: 0.685949\n",
      "Cost after iteration 8000: 0.685787\n",
      "Cost after iteration 9000: 0.685642\n",
      "Cost after iteration 10000: 0.685496\n",
      "Cost after iteration 11000: 0.685338\n",
      "Cost after iteration 12000: 0.685157\n",
      "Cost after iteration 13000: 0.684945\n",
      "Cost after iteration 14000: 0.684691\n",
      "Cost after iteration 15000: 0.684384\n",
      "Cost after iteration 16000: 0.684012\n",
      "Cost after iteration 17000: 0.683559\n",
      "Cost after iteration 18000: 0.683013\n",
      "Cost after iteration 19000: 0.682356\n",
      "Cost after iteration 20000: 0.681568\n",
      "Cost after iteration 21000: 0.680625\n",
      "Cost after iteration 22000: 0.679507\n",
      "Cost after iteration 23000: 0.678182\n",
      "Cost after iteration 24000: 0.676633\n",
      "Cost after iteration 25000: 0.674828\n",
      "Cost after iteration 26000: 0.672755\n",
      "Cost after iteration 27000: 0.670416\n",
      "Cost after iteration 28000: 0.667797\n",
      "Cost after iteration 29000: 0.664932\n",
      "Cost after iteration 30000: 0.661859\n",
      "Cost after iteration 31000: 0.658634\n",
      "Cost after iteration 32000: 0.655268\n",
      "Cost after iteration 33000: 0.651800\n",
      "Cost after iteration 34000: 0.648304\n",
      "Cost after iteration 35000: 0.644831\n",
      "Cost after iteration 36000: 0.641365\n",
      "Cost after iteration 37000: 0.638044\n",
      "Cost after iteration 38000: 0.634847\n",
      "Cost after iteration 39000: 0.631746\n",
      "Cost after iteration 40000: 0.628790\n",
      "Cost after iteration 41000: 0.626058\n",
      "Cost after iteration 42000: 0.623469\n",
      "Cost after iteration 43000: 0.621051\n",
      "Cost after iteration 44000: 0.618784\n",
      "Cost after iteration 45000: 0.616638\n",
      "Cost after iteration 46000: 0.614564\n",
      "Cost after iteration 47000: 0.612541\n",
      "Cost after iteration 48000: 0.610576\n",
      "Cost after iteration 49000: 0.608738\n",
      "Cost after iteration 50000: 0.606982\n",
      "Cost after iteration 51000: 0.605297\n",
      "Cost after iteration 52000: 0.603652\n",
      "Cost after iteration 53000: 0.602091\n",
      "Cost after iteration 54000: 0.600632\n",
      "Cost after iteration 55000: 0.599161\n",
      "Cost after iteration 56000: 0.597658\n",
      "Cost after iteration 57000: 0.596096\n",
      "Cost after iteration 58000: 0.594585\n",
      "Cost after iteration 59000: 0.593037\n",
      "Cost after iteration 60000: 0.591498\n",
      "Cost after iteration 61000: 0.589994\n",
      "Cost after iteration 62000: 0.588526\n",
      "Cost after iteration 63000: 0.586989\n",
      "Cost after iteration 64000: 0.585489\n",
      "Cost after iteration 65000: 0.583974\n",
      "Cost after iteration 66000: 0.582433\n",
      "Cost after iteration 67000: 0.580799\n",
      "Cost after iteration 68000: 0.579094\n",
      "Cost after iteration 69000: 0.577418\n",
      "Cost after iteration 70000: 0.575711\n",
      "Cost after iteration 71000: 0.573873\n",
      "Cost after iteration 72000: 0.572008\n",
      "Cost after iteration 73000: 0.570144\n",
      "Cost after iteration 74000: 0.568189\n",
      "Cost after iteration 75000: 0.566293\n",
      "Cost after iteration 76000: 0.564309\n",
      "Cost after iteration 77000: 0.562175\n",
      "Cost after iteration 78000: 0.560006\n",
      "Cost after iteration 79000: 0.557842\n",
      "Cost after iteration 80000: 0.555736\n",
      "Cost after iteration 81000: 0.553601\n",
      "Cost after iteration 82000: 0.551411\n",
      "Cost after iteration 83000: 0.549253\n",
      "Cost after iteration 84000: 0.547083\n",
      "Cost after iteration 85000: 0.544867\n",
      "Cost after iteration 86000: 0.542596\n",
      "Cost after iteration 87000: 0.540281\n",
      "Cost after iteration 88000: 0.537956\n",
      "Cost after iteration 89000: 0.535612\n",
      "Cost after iteration 90000: 0.533270\n",
      "Cost after iteration 91000: 0.530913\n",
      "Cost after iteration 92000: 0.528535\n",
      "Cost after iteration 93000: 0.526134\n",
      "Cost after iteration 94000: 0.523749\n",
      "Cost after iteration 95000: 0.521361\n",
      "Cost after iteration 96000: 0.518984\n",
      "Cost after iteration 97000: 0.516618\n",
      "Cost after iteration 98000: 0.514250\n",
      "Cost after iteration 99000: 0.511885\n",
      "Cost after iteration 100000: 0.509560\n",
      "Cost after iteration 101000: 0.507264\n",
      "Cost after iteration 102000: 0.504980\n",
      "Cost after iteration 103000: 0.502724\n",
      "Cost after iteration 104000: 0.500473\n",
      "Cost after iteration 105000: 0.498226\n",
      "Cost after iteration 106000: 0.495975\n",
      "Cost after iteration 107000: 0.493738\n",
      "Cost after iteration 108000: 0.491500\n",
      "Cost after iteration 109000: 0.489273\n",
      "Cost after iteration 110000: 0.487052\n",
      "Cost after iteration 111000: 0.484841\n",
      "Cost after iteration 112000: 0.482616\n",
      "Cost after iteration 113000: 0.480417\n",
      "Cost after iteration 114000: 0.478231\n",
      "Cost after iteration 115000: 0.476053\n",
      "Cost after iteration 116000: 0.473894\n",
      "Cost after iteration 117000: 0.471740\n",
      "Cost after iteration 118000: 0.469588\n",
      "Cost after iteration 119000: 0.467458\n",
      "Cost after iteration 120000: 0.465342\n",
      "Cost after iteration 121000: 0.463239\n",
      "Cost after iteration 122000: 0.461156\n",
      "Cost after iteration 123000: 0.459089\n",
      "Cost after iteration 124000: 0.457045\n",
      "Cost after iteration 125000: 0.455026\n",
      "Cost after iteration 126000: 0.453026\n",
      "Cost after iteration 127000: 0.451039\n",
      "Cost after iteration 128000: 0.449074\n",
      "Cost after iteration 129000: 0.447142\n",
      "Cost after iteration 130000: 0.445235\n",
      "Cost after iteration 131000: 0.443359\n",
      "Cost after iteration 132000: 0.441486\n",
      "Cost after iteration 133000: 0.439627\n",
      "Cost after iteration 134000: 0.437786\n",
      "Cost after iteration 135000: 0.435968\n",
      "Cost after iteration 136000: 0.434185\n",
      "Cost after iteration 137000: 0.432429\n",
      "Cost after iteration 138000: 0.430694\n",
      "Cost after iteration 139000: 0.428990\n",
      "Cost after iteration 140000: 0.427321\n",
      "Cost after iteration 141000: 0.425689\n",
      "Cost after iteration 142000: 0.424098\n",
      "Cost after iteration 143000: 0.422542\n",
      "Cost after iteration 144000: 0.421021\n",
      "Cost after iteration 145000: 0.419535\n",
      "Cost after iteration 146000: 0.418085\n",
      "Cost after iteration 147000: 0.416662\n",
      "Cost after iteration 148000: 0.415281\n",
      "Cost after iteration 149000: 0.413934\n",
      "Cost after iteration 150000: 0.412617\n",
      "Cost after iteration 151000: 0.411341\n",
      "Cost after iteration 152000: 0.410100\n",
      "Cost after iteration 153000: 0.408899\n",
      "Cost after iteration 154000: 0.407734\n",
      "Cost after iteration 155000: 0.406596\n",
      "Cost after iteration 156000: 0.405487\n",
      "Cost after iteration 157000: 0.404414\n",
      "Cost after iteration 158000: 0.403376\n",
      "Cost after iteration 159000: 0.402358\n",
      "Cost after iteration 160000: 0.401356\n",
      "Cost after iteration 161000: 0.400381\n",
      "Cost after iteration 162000: 0.399433\n",
      "Cost after iteration 163000: 0.398509\n",
      "Cost after iteration 164000: 0.397593\n",
      "Cost after iteration 165000: 0.396704\n",
      "Cost after iteration 166000: 0.395795\n",
      "Cost after iteration 167000: 0.394888\n",
      "Cost after iteration 168000: 0.393972\n",
      "Cost after iteration 169000: 0.393080\n",
      "Cost after iteration 170000: 0.392168\n",
      "Cost after iteration 171000: 0.391271\n",
      "Cost after iteration 172000: 0.390422\n",
      "Cost after iteration 173000: 0.389566\n",
      "Cost after iteration 174000: 0.388710\n",
      "Cost after iteration 175000: 0.387827\n",
      "Cost after iteration 176000: 0.386972\n",
      "Cost after iteration 177000: 0.386152\n",
      "Cost after iteration 178000: 0.385361\n",
      "Cost after iteration 179000: 0.384597\n",
      "Cost after iteration 180000: 0.383832\n",
      "Cost after iteration 181000: 0.383077\n",
      "Cost after iteration 182000: 0.382333\n",
      "Cost after iteration 183000: 0.381608\n",
      "Cost after iteration 184000: 0.380908\n",
      "Cost after iteration 185000: 0.380226\n",
      "Cost after iteration 186000: 0.379554\n",
      "Cost after iteration 187000: 0.378905\n",
      "Cost after iteration 188000: 0.378282\n",
      "Cost after iteration 189000: 0.377676\n",
      "Cost after iteration 190000: 0.377082\n",
      "Cost after iteration 191000: 0.376493\n",
      "Cost after iteration 192000: 0.375918\n",
      "Cost after iteration 193000: 0.375360\n",
      "Cost after iteration 194000: 0.374824\n",
      "Cost after iteration 195000: 0.374291\n",
      "Cost after iteration 196000: 0.373778\n",
      "Cost after iteration 197000: 0.373209\n",
      "Cost after iteration 198000: 0.372636\n",
      "Cost after iteration 199000: 0.372104\n",
      "Cost after iteration 200000: 0.371591\n",
      "Cost after iteration 201000: 0.371096\n",
      "Cost after iteration 202000: 0.370619\n",
      "Cost after iteration 203000: 0.370156\n",
      "Cost after iteration 204000: 0.369705\n",
      "Cost after iteration 205000: 0.369268\n",
      "Cost after iteration 206000: 0.368847\n",
      "Cost after iteration 207000: 0.368439\n",
      "Cost after iteration 208000: 0.368042\n",
      "Cost after iteration 209000: 0.367656\n",
      "Cost after iteration 210000: 0.367281\n",
      "Cost after iteration 211000: 0.366916\n",
      "Cost after iteration 212000: 0.366561\n",
      "Cost after iteration 213000: 0.366215\n",
      "Cost after iteration 214000: 0.365873\n",
      "Cost after iteration 215000: 0.365513\n",
      "Cost after iteration 216000: 0.365158\n",
      "Cost after iteration 217000: 0.364808\n",
      "Cost after iteration 218000: 0.364468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 219000: 0.364117\n",
      "Cost after iteration 220000: 0.363777\n",
      "Cost after iteration 221000: 0.363442\n",
      "Cost after iteration 222000: 0.363108\n",
      "Cost after iteration 223000: 0.362785\n",
      "Cost after iteration 224000: 0.362467\n",
      "Cost after iteration 225000: 0.362147\n",
      "Cost after iteration 226000: 0.361806\n",
      "Cost after iteration 227000: 0.361470\n",
      "Cost after iteration 228000: 0.361158\n",
      "Cost after iteration 229000: 0.360864\n",
      "Cost after iteration 230000: 0.360582\n",
      "Cost after iteration 231000: 0.360309\n",
      "Cost after iteration 232000: 0.360046\n",
      "Cost after iteration 233000: 0.359793\n",
      "Cost after iteration 234000: 0.359546\n",
      "Cost after iteration 235000: 0.359307\n",
      "Cost after iteration 236000: 0.359075\n",
      "Cost after iteration 237000: 0.358848\n",
      "Cost after iteration 238000: 0.358628\n",
      "Cost after iteration 239000: 0.358407\n",
      "Cost after iteration 240000: 0.358193\n",
      "Cost after iteration 241000: 0.357983\n",
      "Cost after iteration 242000: 0.357781\n",
      "Cost after iteration 243000: 0.357583\n",
      "Cost after iteration 244000: 0.357389\n",
      "Cost after iteration 245000: 0.357200\n",
      "Cost after iteration 246000: 0.357021\n",
      "Cost after iteration 247000: 0.356846\n",
      "Cost after iteration 248000: 0.356674\n",
      "Cost after iteration 249000: 0.356506\n",
      "Cost after iteration 250000: 0.356341\n",
      "Cost after iteration 251000: 0.356178\n",
      "Cost after iteration 252000: 0.356019\n",
      "Cost after iteration 253000: 0.355864\n",
      "Cost after iteration 254000: 0.355712\n",
      "Cost after iteration 255000: 0.355562\n",
      "Cost after iteration 256000: 0.355416\n",
      "Cost after iteration 257000: 0.355273\n",
      "Cost after iteration 258000: 0.355133\n",
      "Cost after iteration 259000: 0.354995\n",
      "Cost after iteration 260000: 0.354861\n",
      "Cost after iteration 261000: 0.354731\n",
      "Cost after iteration 262000: 0.354602\n",
      "Cost after iteration 263000: 0.354475\n",
      "Cost after iteration 264000: 0.354351\n",
      "Cost after iteration 265000: 0.354229\n",
      "Cost after iteration 266000: 0.354109\n",
      "Cost after iteration 267000: 0.353991\n",
      "Cost after iteration 268000: 0.353875\n",
      "Cost after iteration 269000: 0.353760\n",
      "Cost after iteration 270000: 0.353648\n",
      "Cost after iteration 271000: 0.353538\n",
      "Cost after iteration 272000: 0.353429\n",
      "Cost after iteration 273000: 0.353323\n",
      "Cost after iteration 274000: 0.353219\n",
      "Cost after iteration 275000: 0.353118\n",
      "Cost after iteration 276000: 0.353018\n",
      "Cost after iteration 277000: 0.352919\n",
      "Cost after iteration 278000: 0.352820\n",
      "Cost after iteration 279000: 0.352722\n",
      "Cost after iteration 280000: 0.352626\n",
      "Cost after iteration 281000: 0.352531\n",
      "Cost after iteration 282000: 0.352438\n",
      "Cost after iteration 283000: 0.352346\n",
      "Cost after iteration 284000: 0.352255\n",
      "Cost after iteration 285000: 0.352166\n",
      "Cost after iteration 286000: 0.352078\n",
      "Cost after iteration 287000: 0.351992\n",
      "Cost after iteration 288000: 0.351907\n",
      "Cost after iteration 289000: 0.351824\n",
      "Cost after iteration 290000: 0.351741\n",
      "Cost after iteration 291000: 0.351660\n",
      "Cost after iteration 292000: 0.351581\n",
      "Cost after iteration 293000: 0.351504\n",
      "Cost after iteration 294000: 0.351427\n",
      "Cost after iteration 295000: 0.351351\n",
      "Cost after iteration 296000: 0.351273\n",
      "Cost after iteration 297000: 0.351191\n",
      "Cost after iteration 298000: 0.351109\n",
      "Cost after iteration 299000: 0.351029\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on train: \n",
      "Accuracy: 0.818840579710145\n",
      "Performance on test: \n",
      "Accuracy: 0.8150289017341039\n"
     ]
    }
   ],
   "source": [
    "# define network layers\n",
    "layers_dims = [2,5,1] #  2-layer model\n",
    "\n",
    "# run iterative training for 300k epochs (one epoch = one pass through the entire training data)\n",
    "# sidenote: we're running batch gradient descent (all data at once)\n",
    "parameters = L_layer_model(X_train_st, y_train, layers_dims, num_iterations = 300000, learning_rate=0.001, print_cost = True)\n",
    "\n",
    "# use parameters of the NN after 50k epochs to evaluate train and test data \n",
    "print(\"Performance on train: \")\n",
    "pred_train = predict(X_train_st, y_train, parameters)\n",
    "print(\"Performance on test: \")\n",
    "pred_test = predict(X_test_st, y_test, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with sklearn\n",
    "For comparison: using a roughly equivalent sklearn neural network implementation. Notice the much faster runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7971014492753623\n",
      "0.815028901734104\n"
     ]
    }
   ],
   "source": [
    "# for comparison: using roughly equivalent sklearn neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='sgd', learning_rate=\"constant\", alpha=0.001, hidden_layer_sizes=(5,5), \n",
    "                    random_state=1, max_iter=300000)\n",
    "\n",
    "clf.fit(np.swapaxes(X_train_st, 0,1), np.squeeze(y_train))\n",
    "\n",
    "print(clf.score(np.swapaxes(X_train_st, 0,1), np.squeeze(y_train)))\n",
    "print(clf.score(np.swapaxes(X_test_st, 0,1), np.squeeze(y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 7.1 ) Describe the components of a Multi Layer Perceptron.\n",
    "\n",
    "The MLP consists of three types of layers: the input layer, output layer and hidden layer. The input layer receives the input signal to be processed. The required task such as prediction and classification is performed by the output layer. An arbitrary number of hidden layers that are placed in between the input and output layer are the true computational engine of the MLP.\n",
    "\n",
    "- 7.2 ) What do Neural Networks need to have to be able to estimate non-linear relationships in the data?\n",
    "\n",
    "Neural Networks need non-linear activation functions in their layers (softmax, tanh, RELU) to learn non-linear relationships.  \n",
    "\n",
    "- 7.3 ) For a binary classification task on 5 input features; Imagine a deep Neural Network that consists of 3 hidden, fully connected layers with 1000, 500 and 1000 nodes respectively. How many total weights does the network have?\n",
    "\n",
    "Generally:\n",
    "\n",
    "$ Number\\_of\\_Weights =  Weights_{Input} \\times Weights_{H1} + Weights_{H1} \\times Weights_{H2} + Weights_{H2} \\times Weights_{H3} +  Weights_{H3} \\times Output$\n",
    "\n",
    "Considering biases this yields:\n",
    "\n",
    "$ = ((5+1) \\times) + (1001\\times500) + (501\\times1000) + (1001\\times2) = 1009502 $\n",
    "\n",
    "\n",
    "- 7.4 ) Describe a problem that large and very deep Neural Network architectures can have for small data sets.\n",
    "\n",
    "A common problem that arises is $ \\textit{Overfitting} $ of the Neural Network. When the network tries to learn too much or too many details in the training data along with the noise from the training data, it can result in poor performance on unseen data in the test dataset. When this happens, the network fails to generalize the features/patterns found in the training data.\n",
    "\n",
    "- 7.5 ) Describe how the prediction error for the training samples is used to estimate the weights of a deep Neural Network.\n",
    "\n",
    "The impact of the weights of a neural networks are calculated through a $\\textit{back-propagation} $ of the errors.\n",
    "Here, Back-propagation is an automatic differentiation algorithm for calculating the impact of the weights (in form of gradients) in a neural network graph structure. \n",
    "\n",
    "Together with an optimization (learning) algorithm like $ \\textit{Gradient Descent} $, the influence of the prediction errors in the output layer (as defined by a loss function like Cross-Entropy-Loss) for a sample or batch of samples are used to determine the update of each weight of the previous layer. This procedure is repeated layer by layer, back to the first layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T18:06:05.118376Z",
     "start_time": "2022-07-20T18:06:05.097544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1009502"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((5+1) *1000) + (1001*500) + (501*1000) + (1001*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "71b202ce2822e786ea4fdfe3f0305cc84db1dc345efe5c7a2eefa65cade9eecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
